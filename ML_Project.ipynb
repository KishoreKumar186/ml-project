{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       reviewerID        asin              reviewerName   helpful  \\\n",
      "0   AO94DHGC771SJ  0528881469                   amazdnu    [0, 0]   \n",
      "1   AMO214LNFCEI4  0528881469           Amazon Customer  [12, 15]   \n",
      "2  A3N7T0DY83Y4IG  0528881469             C. A. Freeman  [43, 45]   \n",
      "3  A1H8PY3QHMQQA0  0528881469  Dave M. Shaw \"mack dave\"   [9, 10]   \n",
      "4  A24EV6RXELQZ63  0528881469               Wayne Smith    [0, 0]   \n",
      "\n",
      "                                          reviewText  overall  \\\n",
      "0  We got this GPS for my husband who is an (OTR)...      5.0   \n",
      "1  I'm a professional OTR truck driver, and I bou...      1.0   \n",
      "2  Well, what can I say.  I've had this unit in m...      3.0   \n",
      "3  Not going to write a long review, even thought...      2.0   \n",
      "4  I've had mine for a year and here's what we go...      1.0   \n",
      "\n",
      "                                  summary  unixReviewTime   reviewTime  \n",
      "0                         Gotta have GPS!      1370131200   06 2, 2013  \n",
      "1                       Very Disappointed      1290643200  11 25, 2010  \n",
      "2                          1st impression      1283990400   09 9, 2010  \n",
      "3                 Great grafics, POOR GPS      1290556800  11 24, 2010  \n",
      "4  Major issues, only excuses for support      1317254400  09 29, 2011  \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Data Exploration and Preprocessing\n",
    "# 1.1 Load the JSON data and convert it to a pandas DataFrame\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load the JSON data\n",
    "file_path = '/Users/kikumarm/CodeRepo/ML_Project/dataset.json/Electronics_5.json'\n",
    "\n",
    "# Read the file line by line and parse each JSON object\n",
    "data = []\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "# Take only the first 10,000 records\n",
    "data = data[:10000]\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   reviewerID       10000 non-null  object \n",
      " 1   asin             10000 non-null  object \n",
      " 2   reviewerName     9962 non-null   object \n",
      " 3   reviewText       10000 non-null  object \n",
      " 4   overall          10000 non-null  float64\n",
      " 5   summary          10000 non-null  object \n",
      " 6   unixReviewTime   10000 non-null  int64  \n",
      " 7   reviewTime       10000 non-null  object \n",
      " 8   helpful_votes    10000 non-null  int64  \n",
      " 9   unhelpful_votes  10000 non-null  int64  \n",
      "dtypes: float64(1), int64(3), object(6)\n",
      "memory usage: 781.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# 1.2 Remove duplicates and handle missing values\n",
    "# Remove duplicates\n",
    "# Split the 'helpful' column into two separate columns\n",
    "df[['helpful_votes', 'unhelpful_votes']] = pd.DataFrame(df['helpful'].tolist(), index=df.index)\n",
    "\n",
    "# Drop the original 'helpful' column if it's no longer needed\n",
    "df.drop(columns=['helpful'], inplace=True)\n",
    "\n",
    "# Remove duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Display the DataFrame info to confirm duplicates are removed\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   reviewerID       10000 non-null  object \n",
      " 1   asin             10000 non-null  object \n",
      " 2   reviewerName     10000 non-null  object \n",
      " 3   reviewText       10000 non-null  object \n",
      " 4   overall          10000 non-null  float64\n",
      " 5   summary          10000 non-null  object \n",
      " 6   unixReviewTime   10000 non-null  int64  \n",
      " 7   reviewTime       10000 non-null  object \n",
      " 8   helpful_votes    10000 non-null  int64  \n",
      " 9   unhelpful_votes  10000 non-null  int64  \n",
      "dtypes: float64(1), int64(3), object(6)\n",
      "memory usage: 781.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# # Handle missing values (example: fill NaNs with empty strings)\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "# # Display the DataFrame info to check for missing values\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       combined_text\n",
      "0  gotta have gps we got this gps for my husband ...\n",
      "1  very disappointed im a professional otr truck ...\n",
      "2  1st impression well what can i say  ive had th...\n",
      "3  great grafics poor gps not going to write a lo...\n",
      "4  major issues only excuses for support ive had ...\n"
     ]
    }
   ],
   "source": [
    "# 1.3 Clean and normalize text data\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove special characters and lowercase the text\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# Apply the clean_text function to the 'reviewText' and 'summary' columns\n",
    "df['reviewText'] = df['reviewText'].apply(clean_text)\n",
    "df['summary'] = df['summary'].apply(clean_text)\n",
    "\n",
    "# Combine 'summary' and 'reviewText' fields for more context\n",
    "df['combined_text'] = df['summary'] + ' ' + df['reviewText']\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df[['combined_text']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       combined_text  \\\n",
      "0  gotta have gps we got this gps for my husband ...   \n",
      "1  very disappointed im a professional otr truck ...   \n",
      "2  1st impression well what can i say  ive had th...   \n",
      "3  great grafics poor gps not going to write a lo...   \n",
      "4  major issues only excuses for support ive had ...   \n",
      "\n",
      "                                      categories  \n",
      "0                          [Delivery Experience]  \n",
      "1                [Price, Ease of Use, Packaging]  \n",
      "2                         [Price, Functionality]  \n",
      "3  [Product Quality, Functionality, Ease of Use]  \n",
      "4              [Customer Service, Functionality]  \n"
     ]
    }
   ],
   "source": [
    "# 1.4 Create multi-label categories based on review content\n",
    "# Define categories based on common themes in Amazon reviews\n",
    "\n",
    "categories = [\n",
    "    'Product Quality', \n",
    "    'Customer Service', \n",
    "    'Price', \n",
    "    'Functionality', \n",
    "    'Ease of Use', \n",
    "    'Delivery Experience', \n",
    "    'Durability', \n",
    "    'Packaging', \n",
    "    'Value for Money', \n",
    "    'Others'\n",
    "]\n",
    "\n",
    "def categorize_review(text):\n",
    "    labels = []\n",
    "    if any(keyword in text for keyword in ['quality', 'excellent', 'superior', 'poor', 'bad quality']):\n",
    "        labels.append('Product Quality')\n",
    "    if any(keyword in text for keyword in ['service', 'support', 'customer care', 'helpful', 'response']):\n",
    "        labels.append('Customer Service')\n",
    "    if any(keyword in text for keyword in ['price', 'cost', 'expensive', 'cheap', 'affordable']):\n",
    "        labels.append('Price')\n",
    "    if any(keyword in text for keyword in ['function', 'feature', 'performance', 'capability', 'operation']):\n",
    "        labels.append('Functionality')\n",
    "    if any(keyword in text for keyword in ['easy', 'simple', 'user-friendly', 'intuitive', 'convenient']):\n",
    "        labels.append('Ease of Use')\n",
    "    if any(keyword in text for keyword in ['delivery', 'shipping', 'arrival', 'on time', 'late']):\n",
    "        labels.append('Delivery Experience')\n",
    "    if any(keyword in text for keyword in ['durable', 'sturdy', 'long-lasting', 'reliable', 'robust']):\n",
    "        labels.append('Durability')\n",
    "    if any(keyword in text for keyword in ['packaging', 'box', 'wrap', 'sealed', 'damaged packaging']):\n",
    "        labels.append('Packaging')\n",
    "    if any(keyword in text for keyword in ['value', 'worth', 'bang for the buck', 'investment', 'reasonable']):\n",
    "        labels.append('Value for Money')\n",
    "    if not labels:\n",
    "        labels.append('Others')\n",
    "    return labels\n",
    "\n",
    "# Apply the categorize_review function to the 'combined_text' column\n",
    "df['categories'] = df['combined_text'].apply(categorize_review)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df[['combined_text', 'categories']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 12 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   reviewerID       10000 non-null  object \n",
      " 1   asin             10000 non-null  object \n",
      " 2   reviewerName     10000 non-null  object \n",
      " 3   reviewText       10000 non-null  object \n",
      " 4   overall          10000 non-null  float64\n",
      " 5   summary          10000 non-null  object \n",
      " 6   unixReviewTime   10000 non-null  int64  \n",
      " 7   reviewTime       10000 non-null  object \n",
      " 8   helpful_votes    10000 non-null  int64  \n",
      " 9   unhelpful_votes  10000 non-null  int64  \n",
      " 10  combined_text    10000 non-null  object \n",
      " 11  categories       10000 non-null  object \n",
      "dtypes: float64(1), int64(3), object(8)\n",
      "memory usage: 937.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.5 Tokenize and encode text using BERT tokenizer\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Initialize BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Convert the 'combined_text' column to a list\n",
    "texts = df['combined_text'].tolist()\n",
    "\n",
    "# Batch tokenize and encode the text\n",
    "encoded = tokenizer(\n",
    "    texts,\n",
    "    add_special_tokens=True,\n",
    "    max_length=512,\n",
    "    truncation=True,\n",
    "    padding=True,  # Pads to the longest sequence in the batch\n",
    "    return_tensors='np'  # Return NumPy arrays for faster processing\n",
    ")\n",
    "\n",
    "# Add input IDs back to the DataFrame\n",
    "df['input_ids'] = list(encoded['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>unhelpful_votes</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>categories</th>\n",
       "      <th>input_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AO94DHGC771SJ</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>amazdnu</td>\n",
       "      <td>we got this gps for my husband who is an otr o...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>gotta have gps</td>\n",
       "      <td>1370131200</td>\n",
       "      <td>06 2, 2013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gotta have gps we got this gps for my husband ...</td>\n",
       "      <td>[Delivery Experience]</td>\n",
       "      <td>[101, 10657, 2031, 14658, 2057, 2288, 2023, 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMO214LNFCEI4</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>im a professional otr truck driver and i bough...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>very disappointed</td>\n",
       "      <td>1290643200</td>\n",
       "      <td>11 25, 2010</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>very disappointed im a professional otr truck ...</td>\n",
       "      <td>[Price, Ease of Use, Packaging]</td>\n",
       "      <td>[101, 2200, 9364, 10047, 1037, 2658, 27178, 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3N7T0DY83Y4IG</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>C. A. Freeman</td>\n",
       "      <td>well what can i say  ive had this unit in my t...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1st impression</td>\n",
       "      <td>1283990400</td>\n",
       "      <td>09 9, 2010</td>\n",
       "      <td>43</td>\n",
       "      <td>45</td>\n",
       "      <td>1st impression well what can i say  ive had th...</td>\n",
       "      <td>[Price, Functionality]</td>\n",
       "      <td>[101, 3083, 8605, 2092, 2054, 2064, 1045, 2360...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1H8PY3QHMQQA0</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>Dave M. Shaw \"mack dave\"</td>\n",
       "      <td>not going to write a long review even thought ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>great grafics poor gps</td>\n",
       "      <td>1290556800</td>\n",
       "      <td>11 24, 2010</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>great grafics poor gps not going to write a lo...</td>\n",
       "      <td>[Product Quality, Functionality, Ease of Use]</td>\n",
       "      <td>[101, 2307, 22160, 6558, 3532, 14658, 2025, 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A24EV6RXELQZ63</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>Wayne Smith</td>\n",
       "      <td>ive had mine for a year and heres what we got ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>major issues only excuses for support</td>\n",
       "      <td>1317254400</td>\n",
       "      <td>09 29, 2011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>major issues only excuses for support ive had ...</td>\n",
       "      <td>[Customer Service, Functionality]</td>\n",
       "      <td>[101, 2350, 3314, 2069, 21917, 2005, 2490, 492...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin              reviewerName  \\\n",
       "0   AO94DHGC771SJ  0528881469                   amazdnu   \n",
       "1   AMO214LNFCEI4  0528881469           Amazon Customer   \n",
       "2  A3N7T0DY83Y4IG  0528881469             C. A. Freeman   \n",
       "3  A1H8PY3QHMQQA0  0528881469  Dave M. Shaw \"mack dave\"   \n",
       "4  A24EV6RXELQZ63  0528881469               Wayne Smith   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  we got this gps for my husband who is an otr o...      5.0   \n",
       "1  im a professional otr truck driver and i bough...      1.0   \n",
       "2  well what can i say  ive had this unit in my t...      3.0   \n",
       "3  not going to write a long review even thought ...      2.0   \n",
       "4  ive had mine for a year and heres what we got ...      1.0   \n",
       "\n",
       "                                 summary  unixReviewTime   reviewTime  \\\n",
       "0                         gotta have gps      1370131200   06 2, 2013   \n",
       "1                      very disappointed      1290643200  11 25, 2010   \n",
       "2                         1st impression      1283990400   09 9, 2010   \n",
       "3                 great grafics poor gps      1290556800  11 24, 2010   \n",
       "4  major issues only excuses for support      1317254400  09 29, 2011   \n",
       "\n",
       "   helpful_votes  unhelpful_votes  \\\n",
       "0              0                0   \n",
       "1             12               15   \n",
       "2             43               45   \n",
       "3              9               10   \n",
       "4              0                0   \n",
       "\n",
       "                                       combined_text  \\\n",
       "0  gotta have gps we got this gps for my husband ...   \n",
       "1  very disappointed im a professional otr truck ...   \n",
       "2  1st impression well what can i say  ive had th...   \n",
       "3  great grafics poor gps not going to write a lo...   \n",
       "4  major issues only excuses for support ive had ...   \n",
       "\n",
       "                                      categories  \\\n",
       "0                          [Delivery Experience]   \n",
       "1                [Price, Ease of Use, Packaging]   \n",
       "2                         [Price, Functionality]   \n",
       "3  [Product Quality, Functionality, Ease of Use]   \n",
       "4              [Customer Service, Functionality]   \n",
       "\n",
       "                                           input_ids  \n",
       "0  [101, 10657, 2031, 14658, 2057, 2288, 2023, 14...  \n",
       "1  [101, 2200, 9364, 10047, 1037, 2658, 27178, 20...  \n",
       "2  [101, 3083, 8605, 2092, 2054, 2064, 1045, 2360...  \n",
       "3  [101, 2307, 22160, 6558, 3532, 14658, 2025, 21...  \n",
       "4  [101, 2350, 3314, 2069, 21917, 2005, 2490, 492...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      categories  \\\n",
      "0                          [Delivery Experience]   \n",
      "1                [Price, Ease of Use, Packaging]   \n",
      "2                         [Price, Functionality]   \n",
      "3  [Product Quality, Functionality, Ease of Use]   \n",
      "4              [Customer Service, Functionality]   \n",
      "\n",
      "                                           input_ids  \\\n",
      "0  [101, 10657, 2031, 14658, 2057, 2288, 2023, 14...   \n",
      "1  [101, 2200, 9364, 10047, 1037, 2658, 27178, 20...   \n",
      "2  [101, 3083, 8605, 2092, 2054, 2064, 1045, 2360...   \n",
      "3  [101, 2307, 22160, 6558, 3532, 14658, 2025, 21...   \n",
      "4  [101, 2350, 3314, 2069, 21917, 2005, 2490, 492...   \n",
      "\n",
      "                    label_vectors  \n",
      "0  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]  \n",
      "1  [0, 0, 1, 0, 1, 0, 0, 1, 0, 0]  \n",
      "2  [0, 0, 1, 1, 0, 0, 0, 0, 0, 0]  \n",
      "3  [1, 0, 0, 1, 1, 0, 0, 0, 0, 0]  \n",
      "4  [0, 1, 0, 1, 0, 0, 0, 0, 0, 0]  \n"
     ]
    }
   ],
   "source": [
    "# 1.6 Create multi-hot encoded label vectors for the categories\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Initialize MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer(classes=categories)\n",
    "\n",
    "# Fit and transform the categories\n",
    "df['label_vectors'] = list(mlb.fit_transform(df['categories']))\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df[['categories', 'input_ids', 'label_vectors']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>unhelpful_votes</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>categories</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>label_vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AO94DHGC771SJ</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>amazdnu</td>\n",
       "      <td>we got this gps for my husband who is an otr o...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>gotta have gps</td>\n",
       "      <td>1370131200</td>\n",
       "      <td>06 2, 2013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gotta have gps we got this gps for my husband ...</td>\n",
       "      <td>[Delivery Experience]</td>\n",
       "      <td>[101, 10657, 2031, 14658, 2057, 2288, 2023, 14...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMO214LNFCEI4</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>im a professional otr truck driver and i bough...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>very disappointed</td>\n",
       "      <td>1290643200</td>\n",
       "      <td>11 25, 2010</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>very disappointed im a professional otr truck ...</td>\n",
       "      <td>[Price, Ease of Use, Packaging]</td>\n",
       "      <td>[101, 2200, 9364, 10047, 1037, 2658, 27178, 20...</td>\n",
       "      <td>[0, 0, 1, 0, 1, 0, 0, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3N7T0DY83Y4IG</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>C. A. Freeman</td>\n",
       "      <td>well what can i say  ive had this unit in my t...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1st impression</td>\n",
       "      <td>1283990400</td>\n",
       "      <td>09 9, 2010</td>\n",
       "      <td>43</td>\n",
       "      <td>45</td>\n",
       "      <td>1st impression well what can i say  ive had th...</td>\n",
       "      <td>[Price, Functionality]</td>\n",
       "      <td>[101, 3083, 8605, 2092, 2054, 2064, 1045, 2360...</td>\n",
       "      <td>[0, 0, 1, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1H8PY3QHMQQA0</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>Dave M. Shaw \"mack dave\"</td>\n",
       "      <td>not going to write a long review even thought ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>great grafics poor gps</td>\n",
       "      <td>1290556800</td>\n",
       "      <td>11 24, 2010</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>great grafics poor gps not going to write a lo...</td>\n",
       "      <td>[Product Quality, Functionality, Ease of Use]</td>\n",
       "      <td>[101, 2307, 22160, 6558, 3532, 14658, 2025, 21...</td>\n",
       "      <td>[1, 0, 0, 1, 1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A24EV6RXELQZ63</td>\n",
       "      <td>0528881469</td>\n",
       "      <td>Wayne Smith</td>\n",
       "      <td>ive had mine for a year and heres what we got ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>major issues only excuses for support</td>\n",
       "      <td>1317254400</td>\n",
       "      <td>09 29, 2011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>major issues only excuses for support ive had ...</td>\n",
       "      <td>[Customer Service, Functionality]</td>\n",
       "      <td>[101, 2350, 3314, 2069, 21917, 2005, 2490, 492...</td>\n",
       "      <td>[0, 1, 0, 1, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin              reviewerName  \\\n",
       "0   AO94DHGC771SJ  0528881469                   amazdnu   \n",
       "1   AMO214LNFCEI4  0528881469           Amazon Customer   \n",
       "2  A3N7T0DY83Y4IG  0528881469             C. A. Freeman   \n",
       "3  A1H8PY3QHMQQA0  0528881469  Dave M. Shaw \"mack dave\"   \n",
       "4  A24EV6RXELQZ63  0528881469               Wayne Smith   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  we got this gps for my husband who is an otr o...      5.0   \n",
       "1  im a professional otr truck driver and i bough...      1.0   \n",
       "2  well what can i say  ive had this unit in my t...      3.0   \n",
       "3  not going to write a long review even thought ...      2.0   \n",
       "4  ive had mine for a year and heres what we got ...      1.0   \n",
       "\n",
       "                                 summary  unixReviewTime   reviewTime  \\\n",
       "0                         gotta have gps      1370131200   06 2, 2013   \n",
       "1                      very disappointed      1290643200  11 25, 2010   \n",
       "2                         1st impression      1283990400   09 9, 2010   \n",
       "3                 great grafics poor gps      1290556800  11 24, 2010   \n",
       "4  major issues only excuses for support      1317254400  09 29, 2011   \n",
       "\n",
       "   helpful_votes  unhelpful_votes  \\\n",
       "0              0                0   \n",
       "1             12               15   \n",
       "2             43               45   \n",
       "3              9               10   \n",
       "4              0                0   \n",
       "\n",
       "                                       combined_text  \\\n",
       "0  gotta have gps we got this gps for my husband ...   \n",
       "1  very disappointed im a professional otr truck ...   \n",
       "2  1st impression well what can i say  ive had th...   \n",
       "3  great grafics poor gps not going to write a lo...   \n",
       "4  major issues only excuses for support ive had ...   \n",
       "\n",
       "                                      categories  \\\n",
       "0                          [Delivery Experience]   \n",
       "1                [Price, Ease of Use, Packaging]   \n",
       "2                         [Price, Functionality]   \n",
       "3  [Product Quality, Functionality, Ease of Use]   \n",
       "4              [Customer Service, Functionality]   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [101, 10657, 2031, 14658, 2057, 2288, 2023, 14...   \n",
       "1  [101, 2200, 9364, 10047, 1037, 2658, 27178, 20...   \n",
       "2  [101, 3083, 8605, 2092, 2054, 2064, 1045, 2360...   \n",
       "3  [101, 2307, 22160, 6558, 3532, 14658, 2025, 21...   \n",
       "4  [101, 2350, 3314, 2069, 21917, 2005, 2490, 492...   \n",
       "\n",
       "                    label_vectors  \n",
       "0  [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]  \n",
       "1  [0, 0, 1, 0, 1, 0, 0, 1, 0, 0]  \n",
       "2  [0, 0, 1, 1, 0, 0, 0, 0, 0, 0]  \n",
       "3  [1, 0, 0, 1, 1, 0, 0, 0, 0, 0]  \n",
       "4  [0, 1, 0, 1, 0, 0, 0, 0, 0, 0]  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You appear to be using a legacy multi-label data representation. Sequence of sequences are no longer supported; use a binary array or sparse matrix instead - the MultiLabelBinarizer transformer can convert to this format.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m ros = RandomOverSampler()\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Resample the dataset using the 'categories' column\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m X_resampled, y_resampled = \u001b[43mros\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minput_ids\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcategories\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Convert resampled labels (lists of categories) back to multi-hot encoding\u001b[39;00m\n\u001b[32m     19\u001b[39m mlb = MultiLabelBinarizer(classes=categories)  \u001b[38;5;66;03m# Use your predefined list of all possible categories\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CodeRepo/ML_Project/Codebase/.venv/lib/python3.12/site-packages/imblearn/base.py:202\u001b[39m, in \u001b[36mBaseSampler.fit_resample\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit_resample\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, **params):\n\u001b[32m    182\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[32m    183\u001b[39m \n\u001b[32m    184\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    200\u001b[39m \u001b[33;03m        The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[32m    201\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CodeRepo/ML_Project/Codebase/.venv/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CodeRepo/ML_Project/Codebase/.venv/lib/python3.12/site-packages/imblearn/base.py:97\u001b[39m, in \u001b[36mSamplerMixin.fit_resample\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit_resample\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, **params):\n\u001b[32m     74\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[32m     75\u001b[39m \n\u001b[32m     76\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     95\u001b[39m \u001b[33;03m        The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m     arrays_transformer = ArraysTransformer(X, y)\n\u001b[32m     99\u001b[39m     X, y, binarize_y = \u001b[38;5;28mself\u001b[39m._check_X_y(X, y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CodeRepo/ML_Project/Codebase/.venv/lib/python3.12/site-packages/sklearn/utils/multiclass.py:214\u001b[39m, in \u001b[36mcheck_classification_targets\u001b[39m\u001b[34m(y)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcheck_classification_targets\u001b[39m(y):\n\u001b[32m    203\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Ensure that target y is of a non-regression type.\u001b[39;00m\n\u001b[32m    204\u001b[39m \n\u001b[32m    205\u001b[39m \u001b[33;03m    Only the following target types (as defined in type_of_target) are allowed:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    212\u001b[39m \u001b[33;03m        Target values.\u001b[39;00m\n\u001b[32m    213\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     y_type = \u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43my\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    215\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[32m    216\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    217\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmulticlass\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    220\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmultilabel-sequences\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    221\u001b[39m     ]:\n\u001b[32m    222\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    223\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown label type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Maybe you are trying to fit a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    224\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mclassifier, which expects discrete classes on a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    225\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mregression target with continuous values.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    226\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/CodeRepo/ML_Project/Codebase/.venv/lib/python3.12/site-packages/sklearn/utils/multiclass.py:381\u001b[39m, in \u001b[36mtype_of_target\u001b[39m\u001b[34m(y, input_name, raise_unknown)\u001b[39m\n\u001b[32m    375\u001b[39m     \u001b[38;5;66;03m# The old sequence of sequences format\u001b[39;00m\n\u001b[32m    376\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    377\u001b[39m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(first_row_or_val, \u001b[33m\"\u001b[39m\u001b[33m__array__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    378\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(first_row_or_val, Sequence)\n\u001b[32m    379\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(first_row_or_val, \u001b[38;5;28mstr\u001b[39m)\n\u001b[32m    380\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m381\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    382\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mYou appear to be using a legacy multi-label data\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    383\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m representation. Sequence of sequences are no\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    384\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m longer supported; use a binary array or sparse\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    385\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m matrix instead - the MultiLabelBinarizer\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    386\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m transformer can convert to this format.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    387\u001b[39m         )\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[32m    389\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: You appear to be using a legacy multi-label data representation. Sequence of sequences are no longer supported; use a binary array or sparse matrix instead - the MultiLabelBinarizer transformer can convert to this format."
     ]
    }
   ],
   "source": [
    "# STEP 1:\n",
    "# To handle class imbalance in your dataset, you can use techniques like oversampling the minority classes or applying class weights during model training. Here are two common approaches:\n",
    "# 1. Oversampling the Minority Classes\n",
    "# You can use the imblearn library's RandomOverSampler to oversample the minority classes.\n",
    "# 2. Applying Class Weights During Model Training\n",
    "# You can calculate class weights and pass them to the loss function during model training. This approach is useful when using libraries like PyTorch.\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the RandomOverSampler\n",
    "ros = RandomOverSampler()\n",
    "\n",
    "# Resample the dataset using the 'categories' column\n",
    "X_resampled, y_resampled = ros.fit_resample(df['input_ids'], df['categories'])\n",
    "\n",
    "# Convert resampled labels (lists of categories) back to multi-hot encoding\n",
    "mlb = MultiLabelBinarizer(classes=categories)  # Use your predefined list of all possible categories\n",
    "y_resampled_multi_hot = mlb.fit_transform(y_resampled)\n",
    "\n",
    "# Convert back to DataFrame\n",
    "df_resampled = pd.DataFrame({'input_ids': X_resampled, 'label_vectors': list(y_resampled_multi_hot)})\n",
    "\n",
    "# Display the first few rows of the resampled DataFrame\n",
    "print(df_resampled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
